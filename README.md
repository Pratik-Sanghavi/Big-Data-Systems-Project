# **ADAP**ter: Power Efficient Model Inference on Nvidia GPUs
**A**nte Tonkovic-Capin, **D**rishan Poovaya, **A**shu Kumar, **P**ratik Sanghavi

---

## Repository Structure
This repository is part of a broader submission for CS 744 - Big Data Systems for Group 11. The primary submission is the final research report. This repository is any related or supplemental material that we thought worthwhile including as additional source. The repository is structured:

```text
Project
   ├── README.md
   ├── data
   │   └── imagenet_payload.json
   ├── direct_inference
   │   ├── DeepOnxxInference
   │   │   ├── createPayload.py
   │   │   ├── deepOnxxScript.py
   │   │   ├── onxxPython.py
   │   │   ├── onxx_inference.sh
   │   │   ├── payload.json
   │   │   └── serializedImage.txt
   │   ├── repeat-inference.sh
   │   ├── run-tegrastats-tgparse.sh
   │   └── tegra-helper.sh
   ├── power_utils
   │   └── monitor_metrics_tegra.c
   ├── queue_server.py
   ├── queue_server_baseline.py
   ├── send_request.py
   ├── send_request_gpt.py
   └── tgparse.py

   4 directories, 17 files
```

---

## Primary System
The majority of this project's work was done on a UW-Madison machine, 128.105.102.4, running Ubunutu 18.04:

```text
   Static hostname: nvidia-desktop
         Icon name: computer
  Operating System: Ubuntu 18.04.6 LTS
            Kernel: Linux 4.9.299-tegra
      Architecture: arm64
```
Containing a very specific set of dependencies. Therefore the majority of the source code for this project may not be directly transferrable or usable across a broader set of host systems or devices. Those that may be useable or transferrable are detailed in the following sections. Special thank you to Minghao Yan for allowing us the use of his system and device, we hope we kept our part of the bargain and didn't change anything that would cause issues for you after we finished.

---

## Placeholder for ADAPter Code
Maybe write some details on how it could be used on a different system or introduce some of the key portions?

---

## Tegrastats Parsing
We wrote a python utility, `tgparse.py` for parsing the GPU usage data in the log file generated by the `sudo tegrastats` command which can be used by:

```bash
$ python tgparse.py [-h] [-o OUTPUT_FILE] [-i INTERVAL] [-q] log_file
```

We also wrote a bash script, `tegrastats-parse.sh`, that wraps `tgparse.py` and the `sudo tegrastats` command for running, generating and parsing the stats by: 

```bash
$ ./tegrastats-tgparse.sh <interval_in_ms> <count> <output>
```

Which runs the tegrastats utility for the specified count with the interval provided and generates the parsed csv to the output provided.

---

## Contributions
While all the members of ADAP's 11 feel everyone contributed in good faith, per the requirement for specific contributions, see below:

**Ante Tonkovic-Capin**
- Provided emotional support to rest of the group when times were hard
- System config, network and proxy configuration for project dependencies, parsing documentation
- Created sections of Poster
- Wrote sections of Final Report
- Code and Process Documentation
- `tgparse.py`
- `tegrastats-tgparse.sh`
- Parsing data and generating plots

**Drishan Poovaya**
- Provided emotional support to rest of the group when times were hard
- System config, network and proxy configuration for project dependencies, parsing documentation
- Created sections of Poster
- Wrote sections of Final Report

**Ashu Kumar**
- Provided emotional support to rest of the group when times were hard
- System config, network and proxy configuration for project dependencies, parsing documentation
- Created sections of Poster
- Wrote sections of Final Report

**Pratik Sanghavi**
- Provided emotional support to rest of the group when times were hard
- System config, network and proxy configuration for project dependencies, parsing documentation
- Created sections of Poster
- Wrote sections of Final Report

---

## Final Note
Have questions or comments regarding what you see? Don't hesitate to reach out!

**Thank you!**
__- ADAP's 11__